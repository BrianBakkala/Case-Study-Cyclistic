---
title: "Cyclistic Case Study"
output: html_document
date: "2024-06-26"
---

```{r setup, include=FALSE , echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
options(repos = c(CRAN = "https://cran.rstudio.com/"))
```
# Data preparation

## Introduction

In this writeup, we will be taking a look at the ride data for the bike-share company Cyclistic (Divvy), whose stations are in Chicago. Let's look at 12 months of data, from June 2023 to May 2024. The data can be downloaded [here](https://divvy-tripdata.s3.amazonaws.com/index.html).

From this data, we are hoping to learn:
1) How do annual members and casual riders use Cyclistic bikes differently?
2) Why would casual riders buy Cyclistic annual memberships?
3) How can Cyclistic use digital media to influence casual riders to become members?

We can use R to create useful visualizations to help understand our data better and hopefully gain some insights about Cyclistic membership.


## Setting up

Let's install packages and get some libraries up and running.

```{r intro setup, results='hide',fig.keep='all', message = FALSE, warning = FALSE}

#fundamentals
install.packages("tidyverse")  
library(ggplot2) 
library(dplyr) 
library(tidyr)
library(readr)

#Geographic distances
install.packages("geosphere")  
library(geosphere) #geo distance

#Date parsing
library(lubridate)

#Maps
install.packages(c("cowplot", "googleway",  "ggrepel", 
"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata" ))

library("sf")
library("rnaturalearth")
library("rnaturalearthdata") 

install.packages("devtools") 
devtools::install_github("ropensci/rnaturalearthhires")

```

## Let's get a sense of what's going on with this data

Our dataset is split up into multiple files, so let's read each one and combine them.
 
```{r prep data, results='hide',fig.keep='all', message = FALSE, warning = FALSE}
 
df <- list.files(path="202306-divvy-tripdata", full.names = TRUE) %>% 
  grep("\\.csv$", ., value = TRUE) %>% 
  lapply(read_csv) %>% 
  bind_rows 
  
```

Let's do a precursory cleanup ...
 
```{r  clean data, message = FALSE, warning = FALSE}
 
df <- df %>% 
  drop_na()
  
```


...and see what we have.

```{r head, message = FALSE, warning = FALSE}

head(df, 100)
```


### Utility Columns

Some of our data is going to be easier to work with if we pre-compute some expressions. Let's calculate the duration of each bike ride.

```{r  ride duration, message = FALSE, warning = FALSE}
 
#time of ride
df$duration_secs <- as.numeric(difftime(df$ended_at, df$started_at), units = "secs")

```

We can also calculate the distance between the start point and end point. To estimate the actual distance travelled by the rider, we can get the distance "as the crow flies", as well as the so-called [Manhattan distance](https://en.wikipedia.org/wiki/Taxicab_geometry).

```{r ride distances, message = FALSE, warning = FALSE}
great_circle_distances <- numeric(nrow(df))
manhattan_distances <- numeric(nrow(df))

# Calculate distances in chunks
chunk_size <- 20000  # Adjust the chunk size based on system memory capacity
for (i in seq(1, nrow(df), by = chunk_size)) {
  chunk_indices <- i:min(i + chunk_size - 1, nrow(df))
  start_lng_lat <- cbind(df$start_lng[chunk_indices], df$start_lat[chunk_indices])
  end_lng_lat <- cbind(df$end_lng[chunk_indices], df$end_lat[chunk_indices])
  
  manhattan_offset_point <- cbind(df$start_lng[chunk_indices], df$end_lat[chunk_indices])
  
  # Calculate distances for the current chunk
  great_circle_distances[chunk_indices] <- distGeo(start_lng_lat, end_lng_lat)
  manhattan_distances[chunk_indices] <-  distGeo(start_lng_lat, manhattan_offset_point) + distGeo(manhattan_offset_point, end_lng_lat)
  
  #Show progress
  #message <-round(100*i/nrow(df),1)
  #cat(paste(message," "))
  
}

# Assign distances back to the dataframe
df$great_circle_dist_m <- great_circle_distances
df$manhattan_dist_m <- manhattan_distances



```

We can also parse the dates and split their individual components into separate columns
```{r split dates, message = FALSE, warning = FALSE}
  
df$start_year <- year(df$started_at)
df$start_month <- month(df$started_at)
df$start_day <- day(df$started_at)
df$start_hour <- hour(df$started_at)
df$start_day_of_week <- wday(df$started_at, label = TRUE)
df$start_day_is_weekend <- df$start_day_of_week %in% c("Sat", "Sun")


df$end_year <- year(df$ended_at)
df$end_month <- month(df$ended_at)
df$end_day <- day(df$ended_at)
df$end_hour <- hour(df$ended_at)
df$end_day_of_week <- wday(df$ended_at, label = TRUE)
df$end_day_is_weekend <- df$end_day_of_week %in% c("Sat", "Sun")

```

### A strange anomaly
Some rows have the odd characteristic of ending before they start! 

```{r opportunity for data recovery}

#check rides that are shorter than 1 second
time_warp_rides <- df %>%
  filter(duration_secs < 1)

time_warp_rides %>%
  arrange(duration_secs) %>%
  head(100)

#grab rides which are all on the same day
dst_rides <- time_warp_rides %>%
  filter(end_month == 11 &
           end_day == 5 & end_year == 2023 & duration_secs < -100)

head(dst_rides, 100)

```

While many of these are surely errors or equipment malfunctions, a large number of these errors occur in the very early morning on November 5th, 2023. This date and the 2am hour perfectly coincide with the United States Daylight Savings switch. These rows can be offset accordingly, and the data can be reclaimed!

```{r  data recovery}
 
# update the DST-affected ride's durations
# add 1 hour

indices_to_mutate <- df$ride_id %in% dst_rides$ride_id
df$duration_secs[indices_to_mutate] <- df$duration_secs[indices_to_mutate] + (60 * 60)


```


Now that we have some better information about each ride, some erroneous rides can be filtered out.
```{r  remove invalid rows}
 
dataframe <- filter(df, duration_secs>0 & great_circle_dist_m>0 & manhattan_dist_m>0 )

```

### Let's see what we got!

Alright, our data is in much better shape.  

```{r first look}
colnames(dataframe)
head(dataframe,100)

```


# Analysis and Visualization

### What type of bikes do casual riders and members use?

There are three bikes in use: classic, docked, and electric. Let's see if there's a noticeable difference in the way casual riders and members choose bike styles.

```{r bike type}

#Create Labels
rideable_type_labels <- c(
  "classic_bike" = "Classic",
  "docked_bike" = "Docked",
  "electric_bike" = "Electric"
)
member_casual_labels <- c("member" = "Member", "casual" = "Casual")

#Aggregate and count data
df_agg <- dataframe %>%
  group_by(member_casual, rideable_type) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(member_casual) %>%
  mutate(percentage = count / sum(count) * 100) #Calculate percentage of share

# Create the pie charts with facet_wrap
df_agg %>%
  ggplot(aes(x = "", y = count, fill = rideable_type)) +
  geom_bar(stat = "identity",
           width = 1,
           position = "fill") +
  coord_polar(theta = "y") +
  facet_wrap( ~ member_casual, labeller = as_labeller(member_casual_labels)) +
  theme_void() +
  geom_text(aes(label = paste0(round(percentage, 0), "%")),
            position = position_fill(vjust = 0.5),
            size = 3) +
  scale_fill_manual(
    values = c(
      "classic_bike" = "green",
      "docked_bike" = "#ff7f0e",
      "electric_bike" = "yellow"
    ),
    labels = rideable_type_labels
  ) +
  theme(legend.position = "bottom") +
  labs(fill = "Rideable Type",
       title = "Distribution of Rideable Types by Membership Status",
       x = NULL,
       y = NULL)
```

Not really!


### How long does each group ride the bikes?

```{r duration comparison, results='hide',fig.keep='all', message = FALSE, warning = FALSE}

#calculate the medians
medians <- dataframe %>%
  group_by(member_casual) %>%
  summarize(median = median(duration_secs))

#plot
ggplot(data = dataframe, aes(x = duration_secs, fill = member_casual)) +
   geom_vline(data = medians, aes(xintercept = median, color = member_casual),
             linetype = "dashed", linewidth = 1) +
   geom_text(data = medians, aes(x = median, y = Inf, label =paste(round(median, 2),"sec" )             ),
            angle = 90, vjust = 1.5, hjust = 1.1, size = 3, color = "black") +
  geom_histogram(bins = 200, alpha = 0.6) +
  xlim(0, 2500) +
  facet_wrap( ~ member_casual)+
  labs( 
       title = "Distribution of Ride Durations",
       x = "Duration of Ride",
       y = "Number of Rides")


```
In general, casual riders hang onto their bikes for longer, with a median ride length of 767s (12m47s). The member's median ride length is shorter, at 526s (8m46s). However, both groups use the bikes on the majority of their rides for between 300 and 400 seconds. Members may also spend less time navigating the bike-docking system that they are more familiar with, whereas casual riders could potentially spend a chunk of their time docking their bikes, as opposed to riding them.


### How far does each group ride the bikes?

```{r distance comparison, results='hide',fig.keep='all', message = FALSE, warning = FALSE}
# Calculate the medians
medians <- dataframe %>%
  group_by(member_casual) %>%
  summarize(median = median(manhattan_dist_m))

# plot 1
ggplot(data = dataframe, aes(x = manhattan_dist_m, fill = member_casual)) +
  geom_histogram(bins = 200, alpha = 0.6, position = "identity") +
  xlim(0, 6500) +
  facet_wrap(~ member_casual) +
  geom_vline(data = medians, aes(xintercept = median, color = member_casual),
             linetype = "dashed", linewidth = 1) +
  geom_text(data = medians, aes(x = median, y = Inf, label = round(median, 2)),
            angle = 90, vjust = 1.5, hjust = 1.1, size = 3, color = "black") +
  theme_minimal() +
  theme(legend.position = "none")+
  labs( 
       title = "Distribution of Ride Lengths in Manhattan Distance",
       x = "Length of Ride",
       y = "Number of Rides")

medians <- dataframe %>%
  group_by(member_casual) %>%
  summarize(median = median(great_circle_dist_m))
```

```{r distance comparison 2, echo = FALSE, results='hide',fig.keep='all', message = FALSE, warning = FALSE}
#plot 2
ggplot(data = dataframe, aes(x = great_circle_dist_m, fill = member_casual)) +
  geom_histogram(bins = 200, alpha = 0.6, position = "identity") +
  xlim(0, 6500) +
  facet_wrap(~ member_casual) +
  geom_vline(data = medians, aes(xintercept = median, color = member_casual),
             linetype = "dashed", linewidth = 1) +
  geom_text(data = medians, aes(x = median, y = Inf, label = round(median, 2)),
            angle = 90, vjust = 1.5, hjust = 1.1, size = 3, color = "black") +
  theme_minimal() +
  theme(legend.position = "none") +
  labs( 
       title = "Distribution of Ride Lengths 'as the crow flies'",
       x = "Length of Ride",
       y = "Number of Rides")
```


Both groups ride their bikes for similar distances; the medians are in the 1500-1700m range, and both groups peak ~1250m.

### What time of year does each group ride the bikes?

```{r bike time of year}


#Aggregate and count data
df_agg <- dataframe %>%
  group_by(member_casual, start_month) %>%
  summarise(count = n(), .groups = 'drop')

df_agg %>%
  ggplot(aes(
    x = factor(
      start_month,
      levels = 1:length(month.abb),
      labels = month.abb
    ),
    y = count,
    color = member_casual,
    group = member_casual
  )) +
  geom_line() +
  geom_point() +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +  # Adjust the spacing of x-axis labels
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(
    color = "Rideable Type",
    title = "Distribution of Rides by Month and Membership Status",
    x = "Month",
    y = "Count"
  )
```

The shape of each curve is very similar, both members and casual riders prefer to ride in the summer months. Safety concerns due to weather such as ice and snow --not to mention the cold weather-- may explain the low numbers in wintertime.

### What day of the week does each group ride the bikes?

```{r bike day of week}

#Aggregate and count data
df_agg <- dataframe %>%
  group_by(member_casual, start_day_of_week) %>%
  summarise(count = n(), .groups = 'drop')

# Create the  charts with facet_wrap
df_agg %>%
  ggplot(aes(x = start_day_of_week, y = count, fill = member_casual)) +
  
  geom_bar(stat = "identity", width = .9) +
  
  theme(legend.position = "bottom") +
  facet_wrap( ~ member_casual) +
  labs(fill = "Rideable Type",
       title = "Distribution of Rides by day of the week and Membership Status",
       x = NULL,
       y = NULL)
```

Clearly the preference for members is to use the bikes Monday-Friday, and to use them less during the weekend. For casual riders, the opposite is true.

### What time of day does each group ride the bikes?

```{r time of day}

#Create Labels
hour_labels <- c(  "0" = "12a",  "1" = "1a",  "2" = "2a",  "3" = "3a",  "4" = "4a",  "5" = "5a",  "6" = "6a",  "7" = "7a",  "8" = "8a",  "9" = "9a",  "10" = "10a",  "11" = "11a",  "12" = "12p",  "13" = "1p",  "14" = "2p",  "15" = "3p",  "16" = "4p",  "17" = "5p",  "18" = "6p",  "19" = "7p",  "20" = "8p",  "21" = "9p",  "22" = "10p",  "23" = "11p")


#Aggregate and count data
df_agg <- dataframe %>%
  group_by(member_casual, start_hour) %>%
  summarise(count = n(), .groups = 'drop')

# plot
df_agg %>%
  ggplot(aes(
    x = factor(start_hour, levels = 0:23, labels = hour_labels),
    y = count,
    color = member_casual,
    group = member_casual
  )) +
  geom_line() +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +  # Adjust the spacing of x-axis labels
  
  geom_point() +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(
    color = "Rideable Type",
    title = "Distribution of Rides by Hour and Membership Status",
    x = "Hour",
    y = "Count"
  )

```


This graph shows the single most meaningful difference in membervs. usage. The members ride their bikes on their commutes! The huge peaks in the rush-hour times call to mind the classic 9-to-5 workday. To help confirm this theory, we can dive deeper into the workweek, and filter out Saturday and Sunday.


```{r time of day weekend look}

#Aggregate and count 
df_agg <- df %>%
  group_by(member_casual, start_hour, start_day_is_weekend) %>%
  summarise(count = n(), .groups = 'drop')

#plot
df_agg %>%
  ggplot(aes(
    x = factor(start_hour, levels = 0:23, labels = hour_labels),
    y = count,
    color = member_casual,
    group = member_casual
  )) +
  geom_line() +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +  # Adjust the spacing of x-axis labels
  facet_wrap( ~ start_day_is_weekend , labeller = as_labeller(c("FALSE"="Monday – Friday", "TRUE"= "Saturday – Sunday")))+
  geom_point() +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(
    color = "Rideable Type",
    title = "Distribution of Rides by Hour, Membership Status, and Day of the Week",
    x = "Hour",
    y = "Count"
  )

```

Now we can clearly see: there is hardly a perceptible difference between casuals and members during the daylight hours on the weekend. The rush-hour period is a huge area of interest.


## Prepping data for coordinate mapping
```{r prep coords}


# Get relevant cols, and remove cols without precise coordinates
filtered_df <- df[, c(
  "start_station_id",
  "member_casual",
  "end_station_id",
  "start_lat",
  "start_lng",
  "end_lat",
  "end_lng"
)]


# Combine start and end "interactions" into one table
interactions_starts <- filtered_df[, c("member_casual", "start_station_id", "start_lat", "start_lng")]
names(interactions_starts) <- c("member_casual", "station_id", "lat", "lng")

interactions_ends <- filtered_df[, c("member_casual", "start_station_id", "start_lat", "start_lng")]
names(interactions_ends) <- c("member_casual", "station_id", "lat", "lng")

station_interactions_raw <- bind_rows(interactions_starts, interactions_ends)


#Count interactions
station_interactions_temp <- station_interactions_raw %>%
  group_by(station_id, member_casual) %>%
  mutate(station_count = n())


station_interactions_temp <- station_interactions_temp %>%
  mutate(unique_id = paste(member_casual, sep = "_", station_id))

#All rows for same station are now identical
station_interactions <- station_interactions_temp %>%
  distinct(unique_id, station_id, .keep_all = TRUE) %>%
  filter(!is.na(station_id))

 

```




# Geographic Analysis

### Do members and casual riders use bike stations in different neighborhoods?
```{r mapping , results='hide',fig.keep='all', message = FALSE, warning = FALSE }


lakes_data <- ne_download(
  scale = 10,
  type = "lakes_north_america",
  category = "physical",
  destdir = "maps/",
  load = FALSE
)
roads_data <- ne_download(
  scale = 10,
  type = "roads_north_america",
  category = "cultural",
  destdir = "maps/",
  load = FALSE
)

lakes <- ne_load(
  scale = 10,
  type = "lakes",
  destdir = "maps",
  returnclass = "sf"
)
roads <- ne_load(
  scale = 10,
  type = "roads_north_america",
  destdir = "maps",
  returnclass = "sf"
)  %>%
  filter(state == "Illinois")


coordinates_sf <- station_interactions %>% arrange(station_count) %>% st_as_sf(., coords = c("lng", "lat"), crs = 4326)


value_range <- range(station_interactions$station_count, na.rm = TRUE)
breaks <- seq(value_range[1], value_range[2], length.out = 10)


#plot 1
ggplot() +
  geom_sf(data = lakes, fill = "lightblue") +
  geom_sf(data = roads,
          colour = "lightgray",
          linewidth = 0.2) +
  
  facet_wrap(~ member_casual, labeller = as_labeller(member_casual_labels)) +
  geom_sf(data = coordinates_sf, aes(color = station_count), size = 1) +  # Color points based on station_count
  scale_colour_gradient(
    name = 'Station Use' ,
    n.breaks = 5,
    low = "blue",
    high = "red"
  ) +  # Custom color scale
  coord_sf(xlim = c(-87.85, -87.55), ylim = c(41.6, 42.05))  +
  scale_x_continuous(guide = guide_axis(n.dodge = 2))
```



```{r map detail 2, echo = FALSE, results='hide',fig.keep='all', message = FALSE, warning = FALSE}

ggplot() +
  geom_sf(data = lakes, fill = "lightblue") +
  geom_sf(data = roads,
          colour = "lightgray",
          linewidth = 0.2) +
  
  facet_wrap(~ member_casual, labeller = as_labeller(member_casual_labels)) +
  geom_sf(data = coordinates_sf, aes(color = station_count), size = 1.5) +  # Color points based on station_count
  scale_colour_gradient(name = 'Station Use' ,
                        low = "blue",
                        high = "red") +  # Custom color scale
  coord_sf(xlim = c(-87.8, -87.5), ylim = c(41.8, 42.1))  +
  scale_x_continuous(guide = guide_axis(n.dodge = 2))



```

Seems like members and casuals have very similar usage maps.




# Next Steps
## Key takeaways
- Members use their bikes during the workweek, Monday – Friday
- Members use their bikes substantially more during rush-hour times: ~8am and ~5pm
  - Members are likely using their bikes to commute
  
- All riders use their bikes more during the summer months
- Certain neighborhoods get more usage and are "hotspots"



## Recommendations and Audience Targets

### Target casual users who commute
Professionals or students who commute on trains and other public transportation may be interested in more direct alternatives. Students in summer programs may be more receptive to a bike than students during the school year in the fall, winter, and spring.

### Offer seasonal or summer memberships
It's only natural that bike rides are down in the months which are more likely to have wintry conditions. Offering less-than-annual memberships, especially during the summer months, may help persuade those riders who are not willing to commit to riding a bike in Chicago year-round.

### Heat up the cold spots
The hotspot neighborhoods are doing great! But some of the "colder" areas surrounding those hotspots may benefit from additional advertising and promotion.

